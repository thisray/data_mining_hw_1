{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Student Information\n",
    "Name: 李思叡 (Ray)  \n",
    "Student ID: 105065702   \n",
    "GitHub: thisray   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instructions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Download the dataset provided in this [link](https://archive.ics.uci.edu/ml/datasets/Sentiment+Labelled+Sentences#). The sentiment dataset contains a `sentence` and `score` label. Read what the dataset is about on the link provided before you start exploring it. \n",
    "\n",
    "\n",
    "- Then, you are asked to apply each of the data exploration and data operation techniques learned in the [first lab session](https://goo.gl/Sg4FS1) on the new dataset. You don't need to explain all the procedures as we did in the notebook, but you are expected to provide some **minimal comments** explaining your code. You are also expected to use the same libraries used in the first lab session. You are allowed to use and modify the `helper` functions we provided in the first lab session or create your own. Also, be aware that the helper functions may need modification as you are dealing with a completely different dataset. This part is worth 80% of your grade!\n",
    "\n",
    "\n",
    "- After you have completed the operations, you should attempt the **bonus exercises** provided in the [notebook](https://goo.gl/Sg4FS1) we used for the first lab session. There are six (6) additional exercises; attempt them all, as it is part of your grade (10%). \n",
    "\n",
    "\n",
    "- You are also expected to tidy up your notebook and attempt new data operations that you have learned so far in the Data Mining course. Surprise us! This segment is worth 10% of your grade.\n",
    "\n",
    "\n",
    "- After completing all the above tasks, you are free to remove this header block and submit your assignment following the guide provided in the `README.md` file of the assignment's [repository](https://github.com/omarsar/data_mining_hw_1). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "amazon_df: \n",
      "amazon_df.shape: (1000, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>So there is no way for me to plug it in here i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Good case, Excellent value.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Great for the jawbone.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tied to charger for conversations lasting more...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The mic is great.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence  score\n",
       "0  So there is no way for me to plug it in here i...      0\n",
       "1                        Good case, Excellent value.      1\n",
       "2                             Great for the jawbone.      1\n",
       "3  Tied to charger for conversations lasting more...      0\n",
       "4                                  The mic is great.      1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "source count: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1    500\n",
       "0    500\n",
       "Name: score, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "imdb_df: \n",
      "imdb_df.shape: (748, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A very, very, very slow-moving, aimless movie ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Not sure who was more lost - the flat characte...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Attempting artiness with black &amp; white and cle...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Very little music or anything to speak of.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The best scene in the movie was when Gerardo i...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence  score\n",
       "0  A very, very, very slow-moving, aimless movie ...      0\n",
       "1  Not sure who was more lost - the flat characte...      0\n",
       "2  Attempting artiness with black & white and cle...      0\n",
       "3       Very little music or anything to speak of.        0\n",
       "4  The best scene in the movie was when Gerardo i...      1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "source count: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1    386\n",
       "0    362\n",
       "Name: score, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "yelp_df: \n",
      "yelp_df.shape: (1000, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wow... Loved this place.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Crust is not good.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Not tasty and the texture was just nasty.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stopped by during the late May bank holiday of...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The selection on the menu was great and so wer...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence  score\n",
       "0                           Wow... Loved this place.      1\n",
       "1                                 Crust is not good.      0\n",
       "2          Not tasty and the texture was just nasty.      0\n",
       "3  Stopped by during the late May bank holiday of...      1\n",
       "4  The selection on the menu was great and so wer...      1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "source count: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1    500\n",
       "0    500\n",
       "Name: score, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "\n",
    "dataset from: https://archive.ics.uci.edu/ml/datasets/Sentiment+Labelled+Sentences#\n",
    "\n",
    "Score is either 1 (for positive) or 0 (for negative)\n",
    "\n",
    "\"\"\"\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "## load dataset\n",
    "amazon_df = pd.read_csv('./dataset/amazon_cells_labelled.txt', header=None, sep='\\t')\n",
    "imdb_df = pd.read_csv('./dataset/imdb_labelled.txt', header=None, sep='\\t')\n",
    "yelp_df = pd.read_csv('./dataset/yelp_labelled.txt', header=None, sep='\\t')\n",
    "\n",
    "## set columns name\n",
    "column_name = ['sentence', 'score']\n",
    "amazon_df.columns = column_name\n",
    "imdb_df.columns = column_name\n",
    "yelp_df.columns = column_name\n",
    "\n",
    "\n",
    "## display & check shape\n",
    "from IPython.display import display\n",
    "\n",
    "def for_display(df_var, df_name):\n",
    "    print ('{}: '.format(df_name))\n",
    "    print ('{}.shape: {}'.format(df_name, df_var.shape))\n",
    "    display(df_var.head())\n",
    "    print ('source count: ')\n",
    "    display(pd.Series.value_counts(df_var['score']))\n",
    "    print ('\\n')\n",
    "    \n",
    "for_display(amazon_df, 'amazon_df')    \n",
    "for_display(imdb_df, 'imdb_df')    \n",
    "for_display(yelp_df, 'yelp_df')    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### Exercise 0: \n",
    "Experiment with other querying techniques using pandas dataframes. Refer to the their documentation for more information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>So there is no way for me to plug it in here i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Great for the jawbone.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The mic is great.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>If you have several dozen or several hundred c...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Needless to say, I wasted my money.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence  score\n",
       "0  So there is no way for me to plug it in here i...      0\n",
       "2                             Great for the jawbone.      1\n",
       "4                                  The mic is great.      1\n",
       "6  If you have several dozen or several hundred c...      0\n",
       "8                Needless to say, I wasted my money.      0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## first 5 rows  (0~4)\n",
    "amazon_df.head()\n",
    "\n",
    "## last 5 rows\n",
    "amazon_df.tail()\n",
    "\n",
    "## the 5~9 rows\n",
    "amazon_df[5:10]\n",
    "\n",
    "## \"::2\" -> 0, 2, 4, 6, 8 ...\n",
    "## \"[:5]\" -> first 5 rows\n",
    "amazon_df.ix[::2, :][:5]\n",
    "\n",
    "## here only show the last example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### Check missing value  (NaN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "amazon_df has NaN: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False    1000\n",
       "Name: sentence, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "False    1000\n",
       "Name: score, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "imdb_df has NaN: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False    748\n",
       "Name: sentence, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "False    748\n",
       "Name: score, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "yelp_df has NaN: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False    1000\n",
       "Name: sentence, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "False    1000\n",
       "Name: score, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def for_check_nan(df_var, df_name):\n",
    "    check_df = pd.DataFrame(df_var.isnull())\n",
    "    print ('{} has NaN: '.format(df_name))\n",
    "    display(pd.Series.value_counts(check_df['sentence']))\n",
    "    display(pd.Series.value_counts(check_df['score']))\n",
    "    print ('\\n')\n",
    "\n",
    "for_check_nan(amazon_df, 'amazon_df')\n",
    "for_check_nan(imdb_df, 'imdb_df')\n",
    "for_check_nan(yelp_df, 'yelp_df')\n",
    "\n",
    "## -> the result means: no NaN in these 3 dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 1: \n",
    "Code for how to calculate the missing values for every record instead of every column. Hint axis parameter. Check the documentation for more information.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>score</th>\n",
       "      <th>count_nan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sentence  score  count_nan\n",
       "0    False  False          0\n",
       "1    False  False          0\n",
       "2    False  False          0\n",
       "3    False  False          0\n",
       "4    False  False          0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def for_check_nan_each_row(df_var, df_name):\n",
    "    check_df = pd.DataFrame(df_var.isnull())\n",
    "    \n",
    "    def count_nan(row):\n",
    "        count = 0\n",
    "        for element in row:\n",
    "            if element:\n",
    "                count += 1\n",
    "        return count\n",
    "    \n",
    "    check_df['count_nan'] = check_df.apply(lambda x: count_nan(x), axis=1)\n",
    "    \n",
    "    display(check_df.head())\n",
    "\n",
    "\n",
    "for_check_nan_each_row(amazon_df, 'amazon_df')\n",
    "\n",
    "## -> count NaN in each row and record in 'count_nan' column  (only use 'amazon_df' for example)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### Dealing with Duplicate Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(amazon_df['sentence'].duplicated())\n",
    "\n",
    "## ->  result: '10' means there are 10 duplicated rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amazon_df_no_duplicates = amazon_df.drop_duplicates(keep=False, inplace=False)\n",
    "sum(amazon_df_no_duplicates['sentence'].duplicated())\n",
    "\n",
    "## -> remove the duplicated rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Data Preprocessing\n",
    "\n",
    "#### 1 Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "amazon_df_sample: \n",
      "amazon_df_sample.shape: (200, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>433</th>\n",
       "      <td>I highly recommend this modest priced cellular...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>This one works and was priced right.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>I'm still infatuated with this phone.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>710</th>\n",
       "      <td>Can't store anything but phone numbers to SIM.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>worthless product.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              sentence  score\n",
       "433  I highly recommend this modest priced cellular...      1\n",
       "297               This one works and was priced right.      1\n",
       "219              I'm still infatuated with this phone.      1\n",
       "710     Can't store anything but phone numbers to SIM.      0\n",
       "39                                  worthless product.      0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "source count: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    101\n",
       "1     99\n",
       "Name: score, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## sample 'n=200'\n",
    "\n",
    "amazon_df_sample = amazon_df.sample(n=200)\n",
    "for_display(amazon_df_sample, 'amazon_df_sample')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 2: \n",
    "We can also do a side by side comparison of the distribution between the two datasets, but maybe you can try that as an excerise. Look at the Plotly documents for tons of examples and ways to visualizing groups bar charts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x10790c828>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ncwa9JHXOoJekzhn0ktS5/weKq588xx6FmQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1035c6d68>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axes = plt.subplots(nrows=1, ncols=2)\n",
    "\n",
    "amazon_df_sample['score'].value_counts().plot(kind=\"bar\", rot=0, ax=axes[0])\n",
    "\n",
    "amazon_df['score'].value_counts().plot(kind=\"bar\", rot=0, ax=axes[1])\n",
    "\n",
    "\n",
    "## -> try to show the sample result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### 2 Feature Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>score</th>\n",
       "      <th>unigrams</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>So there is no way for me to plug it in here i...</td>\n",
       "      <td>0</td>\n",
       "      <td>[So, there, is, no, way, for, me, to, plug, it...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Good case, Excellent value.</td>\n",
       "      <td>1</td>\n",
       "      <td>[Good, case, ,, Excellent, value, .]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Great for the jawbone.</td>\n",
       "      <td>1</td>\n",
       "      <td>[Great, for, the, jawbone, .]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tied to charger for conversations lasting more...</td>\n",
       "      <td>0</td>\n",
       "      <td>[Tied, to, charger, for, conversations, lastin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The mic is great.</td>\n",
       "      <td>1</td>\n",
       "      <td>[The, mic, is, great, .]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence  score  \\\n",
       "0  So there is no way for me to plug it in here i...      0   \n",
       "1                        Good case, Excellent value.      1   \n",
       "2                             Great for the jawbone.      1   \n",
       "3  Tied to charger for conversations lasting more...      0   \n",
       "4                                  The mic is great.      1   \n",
       "\n",
       "                                            unigrams  \n",
       "0  [So, there, is, no, way, for, me, to, plug, it...  \n",
       "1               [Good, case, ,, Excellent, value, .]  \n",
       "2                      [Great, for, the, jawbone, .]  \n",
       "3  [Tied, to, charger, for, conversations, lastin...  \n",
       "4                           [The, mic, is, great, .]  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "## tokenize_text()  is from 'helper/'\n",
    "def tokenize_text(text, remove_stopwords=False):\n",
    "    tokens = []\n",
    "    for d in nltk.sent_tokenize(text, language='english'):\n",
    "        for word in nltk.word_tokenize(d, language='english'):\n",
    "            tokens.append(word)\n",
    "    return tokens\n",
    "\n",
    "amazon_df['unigrams'] = amazon_df['sentence'].apply(lambda x: tokenize_text(x))\n",
    "\n",
    "amazon_df.head()\n",
    "\n",
    "## -> try to do tokenize, and store the result in 'unigrams' column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### 3 Feature subset selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the', 'mic', 'is', 'great']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "count_vect = CountVectorizer()\n",
    "X_counts = count_vect.fit_transform(amazon_df['sentence'])\n",
    "\n",
    "analyze = count_vect.build_analyzer()\n",
    "analyze(\" \".join(list(amazon_df[4:5].sentence)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The mic is great.'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(\" \".join(amazon_df[4:5].sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 1847)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can check the shape of this matrix by:\n",
    "X_counts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['10', '100', '11', '12', '13', '15', '15g', '18', '20', '2000']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can obtain the feature names of the vectorizer, i.e., the terms\n",
    "count_vect.get_feature_names()[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_counts[0:2,0:100].toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9654.0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## check result\n",
    "temp_view = pd.DataFrame(X_counts.toarray())\n",
    "temp_view[temp_view!=0].sum().sum()\n",
    "\n",
    "## -> try to see how many words in this dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_x = [\"term_\"+str(i) for i in count_vect.get_feature_names()[0:20]]\n",
    "plot_y = [\"doc_\"+ str(i) for i in list(amazon_df.index)[0:20]]\n",
    "plot_z = X_counts[0:20, 0:20].toarray()\n",
    "\n",
    "## -> view 0~19 words' relation with each sentences (doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# to plot\n",
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "import plotly\n",
    "\n",
    "## plot_heat_map() is from 'helpers/'\n",
    "def plot_heat_map(plot_x, plot_y, plot_z):\n",
    "    \"\"\" Helper to plot heat map \"\"\"\n",
    "    trace = {\n",
    "        \"x\": plot_x,\n",
    "        \"y\": plot_y,\n",
    "        \"z\": plot_z,\n",
    "        \"colorscale\": [[0.0, \"rgb(158,1,66)\"], [0.1, \"rgb(213,62,79)\"], [0.2, \"rgb(244,109,67)\"], [0.3, \"rgb(253,174,97)\"], [0.4, \"rgb(254,224,139)\"], [0.5, \"rgb(255,255,191)\"], [0.6, \"rgb(230,245,152)\"], [0.7, \"rgb(171,221,164)\"], [0.8, \"rgb(102,194,165)\"], [0.9, \"rgb(50,136,189)\"], [1.0, \"rgb(94,79,162)\"]],\n",
    "        \"type\": \"heatmap\"\n",
    "    }\n",
    "\n",
    "    data = go.Data([trace])\n",
    "    layout = {\n",
    "        \"legend\": {\n",
    "            \"bgcolor\": \"#F5F6F9\",\n",
    "            \"font\": {\"color\": \"#4D5663\"}\n",
    "        },\n",
    "        \"paper_bgcolor\": \"#F5F6F9\",\n",
    "        \"plot_bgcolor\": \"#F5F6F9\",\n",
    "        \"xaxis1\": {\n",
    "            \"gridcolor\": \"#E1E5ED\",\n",
    "            \"tickfont\": {\"color\": \"#4D5663\"},\n",
    "            \"title\": \"\",\n",
    "            \"titlefont\": {\"color\": \"#4D5663\"},\n",
    "            \"zerolinecolor\": \"#E1E5ED\"\n",
    "        },\n",
    "        \"yaxis1\": {\n",
    "            \"gridcolor\": \"#E1E5ED\",\n",
    "            \"tickfont\": {\"color\": \"#4D5663\"},\n",
    "            \"title\": \"\",\n",
    "            \"titlefont\": {\"color\": \"#4D5663\"},\n",
    "            \"zeroline\": False,\n",
    "            \"zerolinecolor\": \"#E1E5ED\"\n",
    "        }\n",
    "    }\n",
    "\n",
    "    fig = go.Figure(data = data, layout=layout)\n",
    "    return fig\n",
    "\n",
    "## it's not good to show in jupyter notebook\n",
    "# py.iplot(plot_heat_map(plot_x, plot_y, plot_z))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Exercise 3: \n",
    "From the chart above, we can see how sparse the term-document matrix is; i.e., there is only one terms with frequency of 1 in the subselection of the matrix. By the way, you may have noticed that we only selected 20 articles and 20 terms to plot the histrogram. As an excersise you can try to modify the code above to plot the entire term-document matrix or just a sample of it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## ex3\n",
    "plot_x = [\"term_\" + str(i) for i in count_vect.get_feature_names()]\n",
    "plot_y = [\"doc_\" + str(i) for i in list(amazon_df.index)]\n",
    "plot_z = X_counts.toarray()\n",
    "\n",
    "## plot here\n",
    "# py.iplot(plot_heat_map(plot_x, plot_y, plot_z))\n",
    "\n",
    "## -> try to show ALL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "---\n",
    "#### 4 Dimensionality Reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 3)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "X_reduced = PCA(n_components=3).fit_transform(X_counts.toarray())\n",
    "X_reduced.shape\n",
    "\n",
    "## -> We can use PCA to reduce the dimension of data, \n",
    "##    and usually I would use the eigen_value to decide the 'n_components'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "---\n",
    "#### 5 Atrribute Transformation / Aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape:  (1847, 1001)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>991</th>\n",
       "      <th>992</th>\n",
       "      <th>993</th>\n",
       "      <th>994</th>\n",
       "      <th>995</th>\n",
       "      <th>996</th>\n",
       "      <th>997</th>\n",
       "      <th>998</th>\n",
       "      <th>999</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1001 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0  1  2  3  4  5  6  7  8  9  ...    991  992  993  994  995  996  997  \\\n",
       "0  0  0  0  0  0  0  0  0  0  0  ...      0    0    0    0    0    0    0   \n",
       "1  0  0  0  0  0  0  0  0  0  0  ...      0    0    0    0    0    0    0   \n",
       "2  0  0  0  0  0  0  0  0  0  0  ...      0    0    0    0    0    0    0   \n",
       "3  0  0  0  0  0  0  0  0  0  0  ...      0    0    0    0    0    0    0   \n",
       "4  0  0  0  0  0  0  0  0  0  0  ...      0    0    0    0    0    0    0   \n",
       "\n",
       "   998  999  count  \n",
       "0    0    0   19.0  \n",
       "1    0    0    4.0  \n",
       "2    0    0    4.0  \n",
       "3    0    0   12.0  \n",
       "4    0    0    4.0  \n",
       "\n",
       "[5 rows x 1001 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## count the word frequency, and store in the 'count' column\n",
    "\n",
    "term_frequencies_df = pd.DataFrame(X_counts.toarray().T)\n",
    "term_frequencies_df['count'] = term_frequencies_df.sum(axis=0)\n",
    "\n",
    "print ('shape: ', term_frequencies_df.shape)\n",
    "term_frequencies_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 1847)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_counts.toarray().shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 4: \n",
    "The chart above contains all the vocabulary, and it's computationally intensive to both compute and visualize. You can try to reduce the number of terms you want to visualize as an exercise.\n",
    "\n",
    "#### Exercise 5: \n",
    "Additionally, you can attempt to sort the terms on the x-axis by frequency instead of in alphabetical order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>991</th>\n",
       "      <th>992</th>\n",
       "      <th>993</th>\n",
       "      <th>994</th>\n",
       "      <th>995</th>\n",
       "      <th>996</th>\n",
       "      <th>997</th>\n",
       "      <th>998</th>\n",
       "      <th>999</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>29.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>864</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>28.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>28.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>453</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>581</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>26.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1001 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0  1  2  3  4  5  6  7  8  9  ...    991  992  993  994  995  996  997  \\\n",
       "65   0  0  0  0  0  0  0  0  0  0  ...      0    0    0    0    0    0    0   \n",
       "864  0  0  1  0  0  0  0  0  0  0  ...      0    0    0    0    0    0    0   \n",
       "98   0  0  0  0  0  0  0  0  0  0  ...      0    0    0    0    0    0    0   \n",
       "453  0  0  0  0  0  0  0  0  0  0  ...      0    0    0    0    0    0    0   \n",
       "581  0  0  0  0  0  0  0  0  0  0  ...      0    0    0    0    0    0    0   \n",
       "\n",
       "     998  999  count  \n",
       "65     0    0   29.0  \n",
       "864    0    0   28.0  \n",
       "98     0    0   28.0  \n",
       "453    1    0   27.0  \n",
       "581    0    0   26.0  \n",
       "\n",
       "[5 rows x 1001 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## try to sort by 'count' column\n",
    "\n",
    "term_frequencies_df_sort = term_frequencies_df.sort_values(by='count', ascending=False)\n",
    "term_frequencies_df_sort.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Container object of 1847 artists>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD8CAYAAABn919SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nBrokNcJAl6RGGOiS1Ij/B1L45RSnofLmAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11199b470>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## try to plot\n",
    "plt.bar(range(len(term_frequencies_df.index)), term_frequencies_df['count'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### 6 Discretization and Binarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer, OneHotEncoder\n",
    "\n",
    "mlb = LabelBinarizer(neg_label=0, pos_label=1, sparse_output=False)\n",
    "mlb.fit(amazon_df.score)\n",
    "\n",
    "mlb.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>score</th>\n",
       "      <th>unigrams</th>\n",
       "      <th>bin_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>So there is no way for me to plug it in here i...</td>\n",
       "      <td>0</td>\n",
       "      <td>[So, there, is, no, way, for, me, to, plug, it...</td>\n",
       "      <td>[0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Good case, Excellent value.</td>\n",
       "      <td>1</td>\n",
       "      <td>[Good, case, ,, Excellent, value, .]</td>\n",
       "      <td>[1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Great for the jawbone.</td>\n",
       "      <td>1</td>\n",
       "      <td>[Great, for, the, jawbone, .]</td>\n",
       "      <td>[1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tied to charger for conversations lasting more...</td>\n",
       "      <td>0</td>\n",
       "      <td>[Tied, to, charger, for, conversations, lastin...</td>\n",
       "      <td>[0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The mic is great.</td>\n",
       "      <td>1</td>\n",
       "      <td>[The, mic, is, great, .]</td>\n",
       "      <td>[1]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence  score  \\\n",
       "0  So there is no way for me to plug it in here i...      0   \n",
       "1                        Good case, Excellent value.      1   \n",
       "2                             Great for the jawbone.      1   \n",
       "3  Tied to charger for conversations lasting more...      0   \n",
       "4                                  The mic is great.      1   \n",
       "\n",
       "                                            unigrams bin_category  \n",
       "0  [So, there, is, no, way, for, me, to, plug, it...          [0]  \n",
       "1               [Good, case, ,, Excellent, value, .]          [1]  \n",
       "2                      [Great, for, the, jawbone, .]          [1]  \n",
       "3  [Tied, to, charger, for, conversations, lastin...          [0]  \n",
       "4                           [The, mic, is, great, .]          [1]  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amazon_df['bin_category'] = mlb.transform(amazon_df['score']).tolist()\n",
    "amazon_df.head()\n",
    "\n",
    "## some different with Lab01 content (some problems here?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>score</th>\n",
       "      <th>unigrams</th>\n",
       "      <th>bin_category</th>\n",
       "      <th>one-hot_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>So there is no way for me to plug it in here i...</td>\n",
       "      <td>0</td>\n",
       "      <td>[So, there, is, no, way, for, me, to, plug, it...</td>\n",
       "      <td>[0]</td>\n",
       "      <td>[1.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Good case, Excellent value.</td>\n",
       "      <td>1</td>\n",
       "      <td>[Good, case, ,, Excellent, value, .]</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[0.0, 1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Great for the jawbone.</td>\n",
       "      <td>1</td>\n",
       "      <td>[Great, for, the, jawbone, .]</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[0.0, 1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tied to charger for conversations lasting more...</td>\n",
       "      <td>0</td>\n",
       "      <td>[Tied, to, charger, for, conversations, lastin...</td>\n",
       "      <td>[0]</td>\n",
       "      <td>[1.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The mic is great.</td>\n",
       "      <td>1</td>\n",
       "      <td>[The, mic, is, great, .]</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[0.0, 1.0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence  score  \\\n",
       "0  So there is no way for me to plug it in here i...      0   \n",
       "1                        Good case, Excellent value.      1   \n",
       "2                             Great for the jawbone.      1   \n",
       "3  Tied to charger for conversations lasting more...      0   \n",
       "4                                  The mic is great.      1   \n",
       "\n",
       "                                            unigrams bin_category  \\\n",
       "0  [So, there, is, no, way, for, me, to, plug, it...          [0]   \n",
       "1               [Good, case, ,, Excellent, value, .]          [1]   \n",
       "2                      [Great, for, the, jawbone, .]          [1]   \n",
       "3  [Tied, to, charger, for, conversations, lastin...          [0]   \n",
       "4                           [The, mic, is, great, .]          [1]   \n",
       "\n",
       "  one-hot_category  \n",
       "0       [1.0, 0.0]  \n",
       "1       [0.0, 1.0]  \n",
       "2       [0.0, 1.0]  \n",
       "3       [1.0, 0.0]  \n",
       "4       [0.0, 1.0]  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## so I use 'OneHotEncoder()'\n",
    "\n",
    "enc = OneHotEncoder()\n",
    "amazon_df['one-hot_category'] = enc.fit_transform(amazon_df['score'].values.reshape(-1,1)).toarray().tolist()\n",
    "\n",
    "amazon_df.head()\n",
    "\n",
    "\n",
    "## -> this is a method to present the 'catagory data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thanks!\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "\n",
    "I think maybe we can use the 'GitHub Organization', and add every classmates in.\n",
    "\n",
    "Then we can use 'private repository' to push our code to GitHub, and TA still can see them.\n",
    "\n",
    "It's more convenient to TA, and can avoid homework copy.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "print ('thanks!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
